\documentclass[a4paper,11pt]{article}
\usepackage[dutch]{babel}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{xltxtra}

\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

\setmainfont{Bitstream Vera Serif}
\setmonofont{Inconsolata}

\newcommand{\image}[3][1]{
    \begin{figure}
    \begin{center}
    \includegraphics[width=#1\textwidth]{images/#2.pdf}
    \caption{#3}
    \label{fig:#2}
    \end{center}
    \end{figure}
}


\title{Project Algoritmen en Datastructuren III}
\author{Jasper Van der Jeugt}
\date{\today}

\begin{document}

\maketitle
\tableofcontents

\section{Structuur van de code}

\subsection{Verschillende implementaties, dezelfde interface}
\label{interface}

De opgave bestaat eruit om verschillende tools te schrijven met hetzelfde nut,
enkel het gebruikte algoritme is verschillend. Om zoveel mogelijk
code-duplicatie te vermijden, scheiden we daarom de implementatie van de
interface.

Een abstracte interface wordt beschreven in \verb#src/search.h#. Elk algoritme
dient deze interface te implementeren. De interface bevat volgende methoden:

\begin{itemize}
    \item \verb#search_create#: Initialiseert data voor doorzoeken. Afhankelijk
    van het algoritme zal deze functie een aantal variabelen initialiseren.
    \item \verb#search_buffer#: Doorzoek \'e\'en buffer naar de gegeven
    zoekterm.
    \item \verb#search_free#: Ruim op na het zoeken. Hier kan het algoritme
    bepaalde variabelen dealloceren.
\end{itemize}

Deze interface laat toe om elk gevraagd zoekalgoritme te implementeren. We
kunnen nu deze interface drie keer implementeren, met de verschillende
algoritmes. Dit gebeurde in \verb#src/search1.c#, \verb#src/search2.c# en
\verb#src/search3.c#.

Als we deze interface hebben, is het ook mogelijk om door middel van buffers
(zie \ref{buffers}) een functie te schrijven die files doorzoekt. Dit gebeurd in
\verb#src/search-files.c#.

Vervolgens maakt \verb#src/main.c# gebruik van \verb#src/search-files.c# om een
entry point te hebben. De structuur van het programma is dus een soort gelaagde
architectuur zoals ge\"illustreerd in Figuur \ref{fig:layers-main}.

Alle C files (behalve de concrete implementaties) worden dus eens gecompiled met
\verb#src/search1.c#, \verb#src/search2.c# en \verb#search3.c# — zo krijgen we
dus 3 uitvoerbare programma's.

\image[0.6]{layers-main}{Gelaagde architectuur van ons programma}

\subsection{Benchmarking}

Door gebruik te maken van een interface zoals beschreven in \ref{interface},
hebben we ook een manier om makkelijk benchmarks te schrijven. We kunnen opnieuw
gebruik maken van \verb#src/search-files.c#, we moeten enkel de bovenste laag
vervangen. De architectuur van de benchmarks is ge\"illustreerd in Figuur
\ref{fig:layers-bench}.

\image[0.6]{layers-bench}{Gelaagde architectuur van de benchmarks}

Een benchmark zal ook de bestanden die meegegeven zijn op de commandolijn
gebruiken om een string search uit te voeren, met het verschil dat dit meerdere
keren zal uitgevoerd worden, zodat er betrouwbare metingen kunnen gebeuren.
Vervolgens doet het enige postprocessing van de data, zoals bepalen van het
gemiddelde, de standaardafwijking en de uitschieters.

\subsection{Brute force}
\label{brute-force}

We implementeerden ook een eenvoudig brute-force algoritme in het bestand
\verb#src/search0.c#. Dit was niet noodzakelijk maar het interessant om dit te
vergelijken met de andere algoritmes, en het kan ook gebruikt worden in
correctheidstesten.

\subsection{Werken met buffers}
\label{buffers}

Omdat \'e\'en van de vereisten is dat het doorzoeken van grote files mogelijk
is, gebruiken we buffers.

Buffers zijn nodig omdat we nooit het volledige te doorzoeken bestand in \'e\'en
keer in het werkgeheugen kunnen laden als dit groot is. We lezen het dus in per
buffer. In deze subsectie argumenteren we dat we een willekeurig exact string
matching algoritme dat werkt op een simpele array gemakkelijk kunnen uitbreiden
tot een algoritme dat op grote files werkt via buffers.

Onze strategie verloopt als volgt:

\textbf{Gegeven}:

Een initieel lege buffer $b$ met $b_{size}$ de grootte van deze buffer, en
$b_{used}$ het aantal gebruikte tekens in deze buffer. Laat $p$ onze zoekterm
zijn met $p_{size}$ de lengte van deze zoekterm. Verder is $t$ de te
doorzoeken tekst (met lengte $t_{size}$) en $a$ het gebruikte algoritme.

\textbf{Er geldt}:

\begin{itemize}
    \item initieel is de buffer leeg, dus $b_{used} = 0$;
    \item de zoekterm moet in de buffer passen, dus $p_{size} \leq b_{size}$.
\end{itemize}

\textbf{Algoritme}:

\begin{itemize}
    \item Zolang we het einde van de te doorzoeken tekst niet hebben bereikt,
    dus zolang $t$ niet leeg is:
    \begin{itemize}
        \item Verplaats de eerste $b_{size} - b_{used}$ tekens van $t$ naar de
        buffer $b$, de eerste $b_{used}$ tekens van $b$ blijven dus behouden.
        \item Doorzoek $b$ met het gegeven algoritme $a$.
        \item Indien er een match begint op \'e\'en van de
        laatste $p_{size} - 1$ posities in de buffer, kan deze niet gedetecteerd
        worden. Daarom verplaatsen we nu de laatste $p_{size} - 1$ tekens naar
        het begin van $b$. Nu geldt dat $b_{used} = p_{size} - 1$.
    \end{itemize}
\end{itemize}

Er is dus telkens een zeker overlap van $p_{size} - 1$ tekens, die (afhankelijk
van het algoritme) eventueel 2 keer doorzocht wordt, en zeker \'e\'enmaal
gekopi\"eerd. Een slechtste geval analyse geeft ons dat de maximale overhead
gegeven wordt door:

\begin{equation*}
\left( \lceil \frac{t_{size}}{b_{size}} \rceil - 1 \right)
    \cdot \left( p_{size} - 1 \right)
\end{equation*}

Aangezien $p_{size}$ en $t_{size}$ vastliggen, is $b_{size}$ de enige factor
waarmee we de overhead kunnen be\"invloeden. Om de overhead te minimaliseren,
moeten we $b_{size}$ dus zo groot mogelijk kiezen.

Wat is nu concreet een goede buffergrootte? Als we voor een vaste zoekterm (20
bytes, random) in een vaste tekst (200 bytes, random) zoeken, zien we dat de
uitvoeringstijd inderdaad omgekeerd evenredig is met de buffergrootte (zie
Figuur \ref{fig:plot-buffer-size}). We kiezen daarom $b_{size} = 65536$, omdat
grotere buffer sizes niet veel verschil meer zullen maken.

\image{plot-buffer-size}{We zien dat de uitvoeringstijd omgekeerd evenredig is
met de buffergrootte}

\section{Shift-and}

\subsection{Strategie bij langere zoekpatronen}

Stel $b$ gelijk aan het aantal bits in een \verb#unsigned long long#.

Een belangrijke vraag bij het shift-and algoritme is welke strategie we
gebruiken indien het $p_{size} > b$. We bestuderen twee mogenlijkheden:

\begin{itemize}
    \item We gebruiken gewoon een \verb#unsigned long long#, en kijken initieel
    enkel naar de eerste $b$ bytes van $p$. Indien deze matchen gebruiken we een
    brute-force algoritme om de laatste $p_{size} - b$ bytes te matchen.
    \item We gebruiken een abstracte \verb$bit_vector$ structuur. Dit is
    ge\"implementeerd in \verb#src/bit-vector.c#. Deze kan zoekpatronen van
    arbitraire lengte aan, weliswaar met een zekere overhead.
\end{itemize}

We onderzoeken de overhead. Wanneer we een korte zoekterm gebruiken, is er
duidelijk een zeer grote overhead (zie Figuur \ref{fig:plot-bit-vector}).
We kiezen er dus voor om brute force te gebruiken in de implementatie.
De bitvector-gebaseerde implementatie is terug te vinden in
\verb#src/search1-bit-vector.c# als referentie.

\image{plot-bit-vector}{We vergelijken het gebruik van een bitvector structuur
(blauw) bij shift-and met het gebruik van brute force(rood). We laten de
tekstgrootte vari\"eren voor een vaste zoektermgrootte (20 bytes). Het is
duidelijk dat de overhead bij een bitvector zeer groot is.}

\section{Knuth-Morris-Prath}

\subsection{Uitbreiden van verschuivingstabel}

Een belangrijke vraag is wat we doen als we een match vinden. Een na\"ieve
implementatie zou kunnen zijn: de huidige positie met \'e\'en verhogen, en het
aantal gelijke tekens terug gelijk te stellen aan 0.

Stel echter dat er op elke positie van tekst een match voorkomt. Dan is het
eenvoudig om te zien dat de tijdscomplexiteit algoritme nu een bovengrens heeft
van $O(m \cdot n)$. Dit willen we niet, aangezien het voordeel van KMP net is
dat het altijd in $O(m + n)$ tijd kan.

Onze oplossing bestaat eruit om onze verschuivingstabel \'e\'en element groter
te maken. De betekenis van dit laatste element is analoog met de betekenis van
de laatste elementen: het duidt op het aantal karakters dat men mag overslaan
als de eerste mismatch op deze positie voorkomt — dus, als de volledige string
matcht (aangezien we nooit verder zullen vergelijken dan de stringlengte).

Bij het “barbados” voorbeeld wordt dit:

\begin{center}
\begin{tabular}{lllllllll}
b & a & r & b & a & d & o & s &   \\
1 & 1 & 2 & 3 & 3 & 3 & 6 & 7 & 8 \\
\end{tabular}
\end{center}

Het instellen van dit element verloopt volledig analoog met de vorige elementen,
we laten dus gewoon de lus waarin we de verschuivingstabel opstellen \'e\'en
element verder lopen.

\section{Horspool}

Als derde algoritme twijfelde ik initieel tussen Rabin-Karp en Horspool. Na
enkele tests te draaien bleek Horspool echter veel sneller voor de meeste
gevallen, dus koos ik hiervoor.

De implementatie van Horspool is zeer eenvoudig en straightforward — dit is een
van de redenen dat dit algoritme zo snel is, er worden nauwelijks complexe
berekeningen gedaan.

Als we de \verb#buffer# variabele zo kiezen dat deze steeds naar het laatste
karakter wijst, moeten we ook nauwelijks pointer aritmetiek toepassen, enkel in
het geval dat er een match is moeten we enkele aritmetische operaties uitvoeren.

\section{Algemene optimalisaties}

\subsection{Dereferencing versnellen}

In alle algoritmes lopen we door de buffer om de string te zoeken. De klassieke
manier om dit te doen wordt in C geschreven als:

\begin{verbatim}
int i;
for(i = 0; i < buffer_size; i++) {
    /* Doe iets met buffer[i]... */
}
\end{verbatim}

In de meeste gevallen wordt \verb#buffer[i]# zeer intensief gebruikt in de body
van de lus. We kunnen dit echter ook schrijven als:

\begin{verbatim}
const char *buffer_end = buffer + buffer_size;
while(buffer < buffer_end) {
    /* Doe iets met *buffer... */
    buffer++;
}
\end{verbatim}

De waarde van \verb#*buffer# bepalen gaat sneller dan de waarde van
\verb#buffer[i]# bepalen, omdat er geen optelling nodig is. Aangezien deze
optelling meerdere keren zou gebeuren in de body van de lus, en de lus een groot
aantal keer uitgevoerd wordt, is dit een optimalisatie die de moeite loont: alle
ge\"implementeerde algoritmen werden ongeveer 10\% sneller voor voldoende grote
bestanden.

\subsection{Gebruik van globale variabelen}

De abstracte interface in \verb#src/search.h# voorziet de volgende methoden:

\begin{itemize}
    \item \verb#search_create#
    \item \verb#search_buffer#
    \item \verb#search_free#
\end{itemize}

Als we bijvoorbeeld KMP implementeren, zullen we in de \verb#search_create#
methode onze verschuivingstabel opstellen. We hebben deze verschuivingstabel
echter nodig in \verb#search_buffer# — hoe geven we deze variabelen door?

Onze eerste oplossing bestond eruit om een \verb#struct search_state# te
declareren in \verb#src/search.h#, en de verschillende algoritmes konden
deze state dan implementeren zoals gewenst (b.v. een verschuivingstabel,
of een bitvector erin opslaan). Deze \verb#struct# werkt dan aangemaakt in
\verb#search_create#, en doorgegeven aan de andere twee functies.

Een andere, en — vanuit een software-engineering standpunt — lelijkere methode
bestaat eruit om al deze state op te slaan in globale variabelen. Maar, op die
manier werd de code wel ongeveer 8\% sneller, doordat we b.v.
\verb#skip_table[i]# konden gebruiken in plaats van \verb#state->skip_table[i]#.

Het grote probleem met globale variabelen hier is dat ons algoritme volledig zou
crashen indien we het later in een multithreaded programma zouden gebruiken.
Stel bijvoorbeeld dat we de globale variabelen vanuit \'e\'en thread zouden
overschrijven tijdens dat een andere thread ze nog gebruikt.

Onze uiteindelijke algoritmes nemen de gulden middelweg: we gebruiken wel een
\verb#struct search_state# die we doorgeven, maar we maken telkens in de
methoden ook een referentie aan naar de velden hiervan.

\section{Correctheidstesten}

\subsection{Testen op valse positieven}

Bij een exact string matching algoritme is het zeer makkelijk om te testen op
valse positieven. Concreet is een vals positief hier wanneer ons algoritme dat
er een match staat in file $f$ op positie $p$, en dit niet het geval is.

We schreven een tool om dit te testen, de source code hiervan is te vinden in
\verb#util/verify-matches.c#. Deze tool neemt op \verb#stdin# een aantal lijnen
van de form \verb#file_name:position#, dus de uitvoer van \'e\'en van de
zoekalgoritmes. Vervolgens zal het \'e\'en voor \'e\'en alle files openen,
zoeken naar de gegeven positie, en kijken of de zoekterm hier effectief staat.

\subsection{Parallel testen van verschillende algoritmes}

Alle verschillende algoritmes die we ge\"implementeerd hebben dienen exact
hetzelfde resultaat te geven voor dezelfde input. We kunnen dus een soort
algemene test implementeren die alle algoritmes probeert op \'e\'en inputset, en
vervolgens de uitkomsten vergelijkt.

Bovendien kunnen we gebruik maken van named pipes om een oneindig grote tekst
te genereren. Dit controleert dan ook of de buffering goed werkt — want een
oneindig groot bestand kan nooit in het werkgeheugen passen. Ook kunnen de
verschillende algoritmes parallel draaien, wat een voordeel is op moderne
multicore processors.

Hiertoe gebruiken we de utilities \verb#pipe-diff# (zie \ref{pipe-diff}) en
\verb#generate-text-and-matches# (zie \ref{generate-text-and-matches}).

We genereren voor een bepaalde zoekterm een stroom van tekst, en laten
alle zoekalgoritmes erop los. Voor $x$ zoekalgoritmen krijgen we dus $x$
outputstromen met posities, en van \verb#generate-text-and-matches# krijgen we
nog 1 outputstroom met de verwachte posities. Vervolgens vergelijken we al deze
stromen met de \verb#pipe-diff# utility.

Het eenvoudige ruby-scriptje dat al deze stromen aanmaakt en opstart kan worden
teruggevonden in \verb#util/parallel-test.rb#. In principe kan deze test eeuwig
draaien, het geheugengebruik blijft constant — we kunnen dit dus enkele
nachten laten draaien, zo zijn we er vrij zeker van dat onze algoritmes werken.

\subsection{Eenvoudigweg vergelijken}

We kunnen ook een eenvoudigere test schrijven, \'e\'en die simpelweg twee
algoritmes sequentieel start, en de resultaten vergelijkt met een klassieke
\verb#diff#. Dit is ge\"implementeerd in het eenvoudige ruby-scriptje
\verb#util/comparing-test.rb#. Het gebruikt de \verb#generate-text# (zie
\ref{generate-text}) om willekeurige zoekpatronen en teksten aan te maken.

Welke twee algoritmes vergeleken moeten worden, kan de gebruiker meegeven op de
commandolijn.

\subsection{Overlappende matches}

Een geval waar het eventueel fout zou kunnen gaan zijn overlappende matches. Om
dit te testen schreven we een klein ruby-scriptje in
\verb#util/overlapping-test.rb#, dat een bestand genereerd met zeer veel
overlappende matches. Een voorbeeld van zo'n geval:

\begin{center}
\begin{tabular}{llllllllll}
Tekst:   & t & a & m & t & a & m & t & a & m \\
Match 1: & t & a & m & t & a & m &   &   &   \\
Match 2: &   &   &   & t & a & m & t & a & m \\
\end{tabular}
\end{center}

Dit scriptje zal zo'n bestand aanmaken en de verschillende algoritmes erop
loslaten. Het kan zelf eenvoudig de matches voorspellen (vanwege het patroon in
de tekst), dus het zal de gevonden matches daarmee vergelijken.

\section{Snelheidstesten}

In deze sectie vergelijken we de snelheid van de algoritmes, toegepast op een
aantal veel voorkomende gevallen en een aantal interessante gevallen.

\subsection{Worst-case scenario}

In deze subsectie bekijken we de snelheid van de verschillende algoritmes in
een zeer nadelig scenario: we zoeken een term van het formaat \verb#aa...aab#
in een tekst van hetzelfde formaat (een worst-case voor brute-force dus). We
laten de zoektermgrootte vari\"eren van zeer kort tot bijna de lengte van het
tekstbestand.

Voor ons brute-force algoritme (zie \ref{brute-force}) krijgen we een grafiek
(zie Figuur \ref{fig:plot-worst-case-brute-force}) die eenvoudig te verklaren
is. Eerst bekijken we de linkerhelft van de grafiek: naarmate de zoekterm langer
wordt, stijgt de uitvoeringstijd — dit is inherent aan brute force. In de
rechterhelft zien we dat de uitvoeringstijd hierna weer daalt. Dit is omdat
als de zoekterm zeer groot wordt, er slechts weinig posities zijn op welke de
zoekterm kan voorkomen (hij moet immers binnen de tekst passen...).

\image{plot-worst-case-brute-force}{Uitvoeringstijd van het brute-force
algoritme bij een worst-case scenario}

Als we de uitvoeringstijden van de andere algoritmen plotten krijgen we een
grafiek zoals in Figuur \ref{fig:plot-worst-case}. We kunnen zien dat shift-and
relatief trager is dan de andere algoritmen — de grafiek lijkt zeer sterk op
deze van brute-force. Dit is eenvoudig te verklaren, shift-and is in essentie
gewoon een optimalisatie van brute-force met een constante factor.

\image{plot-worst-case}{Uitvoeringstijden van de verschillende algoritmen voor
een worst-case scenario. Shift-and wordt in het rood aangeduid, KMP in het
blauw, en Horspool in het groen}

\image{plot-worst-case-detail}{Uitvoeringstijden van de verschillende algoritmen
voor een worst-case scenario. KMP wordt in het blauw aangeduid, en Horspool in
het groen}

We bekijken nu de uitvoeringstijden van KMP en Horspool in detail (zie Figuur
\ref{fig:plot-worst-case-detail}). We kunnen de lineaire complexiteit van KMP
hier mooi ge\"illustreerd zien. De uitvoeringstijden van Horspool worden kleiner
voor grotere zoektermen, maar dit is enkel omdat Horspool eerst naar het laatste
karakter kijkt — dit is dus een uitzonderingsgeval, gegeven de speciale
zoekterm.

\section{Utilities}

\subsection{Genereren van willekeurige tekst}
\label{generate-text}

We schreven een utility om willekeurige tekst te genereren. Dit is handig bij
het testen van de verschillende algoritmes.

De source code hiervan is te vinden in \verb#util/generate-text.c#. De gebruiker
kan meegeven welke karakters er gebruikt moeten worden in de willekeurige tekst
(b.v. enkel alfanumeriek, of een DNA sequentie) en hoeveel tekst er gegenereerd
moet worden.

\label{generate-text-and-matches}
Een variant bevindt zich in \verb#util/generate-text-and-matches.c#. Deze zal
naast een willekeurige tekst ook nog de verwachte matches (dus de posities
waarop een match moet voorkomen) genereren.

\subsection{Vergelijken van pipes}
\label{pipe-diff}

Om verschillende bestanden te vergelijken, gebruikt men klassiek het \verb#diff#
programma. Dit werkt echter niet goed als het de bedoeling is om named pipes
te vergelijken. Om dit op te lossen schreven we \verb#util/pipe-diff.hs#. Deze
utility is geschreven in Haskell, omdat die programmeertaal op een eenvoudige
manier threads en concurrent IO toelaat, wat nodig is als we de output van
verschillende pipes tegelijk willen vergelijken.

De utility neemt een aantal bestanden als argumenten, en zal al deze bestanden
lijn voor lijn vergelijken — ze dienen allemaal hetzelfde te zijn. Het heeft de
aangename eigenschap om ook zeer goed te werken op named pipes.

\end{document}
