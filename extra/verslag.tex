\documentclass[a4paper,11pt]{article}
\usepackage[dutch]{babel}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{xltxtra}

\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

\setmainfont{Bitstream Vera Serif}
\setmonofont{Inconsolata}

\title{Project Algoritmen en Datastructuren III}
\author{Jasper Van der Jeugt}
\date{\today}

\begin{document}

\maketitle
\tableofcontents

\section{Structuur van de code}

\subsection{Verschillende implementaties, dezelfde interface}

De opgave bestaat eruit om verschillende tools te schrijven met hetzelfde nut,
enkel het gebruikte algoritme is verschillend. Om zoveel mogelijk
code-duplicatie te vermijden, scheiden we daarom de implementatie van de
interface.

Een abstracte interface wordt beschreven in \verb#src/search.h#. Elk algoritme
dient deze interface te implementeren. De interface bevat volgende methoden:

\begin{itemize}
    \item \verb#search_create#: Initialiseert data voor doorzoeken. Afhankelijk
    van het algoritme zal deze functie een aantal variabelen initialiseren.
    \item \verb#search_buffer#: Doorzoek \'e\'en buffer naar het gegeven
    zoekpatroon.
    \item \verb#search_free#: Ruim op na het zoeken. Hier kan het algoritme
    bepaalde variabelen dealloceren.
\end{itemize}

Deze interface laat toe om elk gevraagd zoekalgoritme te implementeren. We
kunnen nu de verschillende algoritmes implementeren in \verb#src/search1.c#,
\verb#src/search2.c# en \verb#src/search3.c#, en de algemene code in
\verb#src/main.c#. Na compilatie kunnen we dan het gewenste algoritme linken met
de algemene code.

\subsection{Werken met buffers}

Omdat \'e\'en van de vereisten is dat het doorzoeken van grote files mogelijk
is, gebruiken we buffers. In deze subsectie argumenteren we aan dat we een
willekeurig exact string matching algoritme dat werkt op een simpele array
gemakkelijk kunnen uitbreiden tot een algoritme dat op grote files werkt via
buffers.

Onze strategie verloopt als volgt:

\textbf{Gegeven}:

Een initieel lege buffer $b$ met $b_{size}$ de grootte van deze buffer, en
$b_{used}$ het aantal gebruikte tekens in deze buffer. Laat $p$ ons zoekpatroon
zijn met $p_{size}$ de lengte van dit zoekpatroon. Verder is $t$ de te
doorzoeken tekst (met lengte $t_{size}$) en $a$ het gebruikte algoritme.

\textbf{Er geldt}:

\begin{itemize}
    \item initieel is de buffer leeg, dus $b_{used} = 0$;
    \item het patroon moet in de buffer passen, dus $p_{size} \leq b_{size}$.
\end{itemize}

\textbf{Algoritme}:

\begin{itemize}
    \item Zolang we het einde van de te doorzoeken tekst niet hebben bereikt,
    dus zolang $t$ niet leeg is:
    \begin{itemize}
        \item Verplaats de eerste $b_{size} - b_{used}$ tekens van $t$ naar de
        buffer $b$, de eerste $b_{used}$ tekens van $b$ blijven dus behouden.
        \item Doorzoek $b$ met het gegeven algoritme $a$.
        \item Indien er een match begint op \'e\'en van de
        laatste $p_{size} - 1$ posities in de buffer, kan deze niet gedetecteerd
        worden. Daarom verplaatsen we nu de laatste $p_{size} - 1$ tekens naar
        het begin van $b$. Nu geldt dat $b_{used} = p_{size} - 1$.
    \end{itemize}
\end{itemize}

Er is dus telkens een zeker overlap van $p_{size} - 1$ tekens, die (afhankelijk
van het algoritme) eventueel 2 keer doorzocht wordt. Een slechtste geval analyse 
geeft ons dat de maximale overhead gegeven wordt door:

\begin{equation*}
\left( \lceil \frac{t_{size}}{b_{size}} \rceil - 1 \right)
    \cdot \left( p_{size} - 1 \right)
\end{equation*}

Aangezien $p_{size}$ en $t_{size}$ vastliggen, is $b_{size}$ de enige factor
waarmee we de overhead kunnen be\"invloeden. Om de overhead te minimaliseren,
moeten we $b_{size}$ zo groot mogelijk kiezen.

\section{Algemene optimalisaties}

\subsection{Dereferencing versnellen}

In alle algoritmes lopen we door de buffer om de string te zoeken. De klassieke
manier om dit te doen wordt in C geschreven als:

\begin{verbatim}
int i;
for(i = 0; i < buffer_size; i++) {
    /* Doe iets met buffer[i]... */
}
\end{verbatim}

In de meeste gevallen wordt \verb#buffer[i]# zeer intensief gebruikt in de body
van de lus. We kunnen dit echter ook schrijven als:

\begin{verbatim}
const char *buffer_end = buffer + buffer_size;
while(buffer < buffer_end) {
    /* Doe iets met *buffer... */
    buffer++;
}
\end{verbatim}

De waarde van \verb#*buffer# bepalen gaat sneller dan de waarde van
\verb#buffer[i]# bepalen, omdat er geen optelling nodig is. Aangezien deze
optelling meerdere keren zou gebeuren in de body van de lus, en de lus een groot
aantal keer uitgevoerd wordt, is dit een optimalisatie die de moeite loont: alle
ge\"implementeerde algoritmen werden ongeveer 10\% sneller voor voldoende grote
bestanden.

\section{Correctheidstesten}

\subsection{Testen op valse positieven}

Bij een exact string matching algoritme is het zeer makkelijk om te testen op
valse positieven. Concreet is een vals positief hier wanneer ons algoritme dat
er een match staat in file $f$ op positie $p$, en dit niet het geval is.

We schreven een tool om dit te testen, de source code hiervan is te vinden in
\verb#util/verify-matches.c#. Deze tool neemt op \verb#stdin# een aantal lijnen
van de form \verb#file_name:position#, dus de uitvoer van \'e\'en van de
zoekalgoritmes. Vervolgens zal het \'e\'en voor \'e\'en alle files openen,
zoeken naar de gegeven positie, en kijken of de zoekterm hier effectief staat.

\section{Utilities}

\subsection{Genereren van willekeurige tekst}

We schreven een utility om willekeurige tekst te genereren. Dit is handig bij
het testen van de verschillende algoritmes.

De source code hiervan is te vinden in \verb#util/generate-text.c#. De gebruiker
kan meegeven welke karakters er gebruikt moeten worden in de willekeurige tekst
(b.v. enkel alfanumeriek, of een DNA sequentie) en hoeveel tekst er gegenereerd
moet worden.

\end{document}
