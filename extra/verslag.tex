\documentclass[a4paper,11pt]{article}
\usepackage[dutch]{babel}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{xltxtra}

\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

\setmainfont{Bitstream Vera Serif}
\setmonofont{Inconsolata}

\newcommand{\image}[3][1]{
    \begin{figure}
    \begin{center}
    \includegraphics[width=#1\textwidth]{images/#2.pdf}
    \caption{#3}
    \label{fig:#2}
    \end{center}
    \end{figure}
}


\title{Project Algoritmen en Datastructuren III}
\author{Jasper Van der Jeugt}
\date{\today}

\begin{document}

\maketitle
\tableofcontents

\section{Structuur van de code}

\subsection{Verschillende implementaties, dezelfde interface}
\label{interface}

De opgave bestaat eruit om verschillende tools te schrijven met hetzelfde nut,
enkel het gebruikte algoritme is verschillend. Om zoveel mogelijk
code-duplicatie te vermijden, scheiden we daarom de implementatie van de
interface.

Een abstracte interface wordt beschreven in \verb#src/search.h#. Elk algoritme
dient deze interface te implementeren. De interface bevat volgende methoden:

\begin{itemize}
    \item \verb#search_create#: Initialiseert data voor doorzoeken. Afhankelijk
    van het algoritme zal deze functie een aantal variabelen initialiseren.
    \item \verb#search_buffer#: Doorzoek \'e\'en buffer naar het gegeven
    zoekpatroon.
    \item \verb#search_free#: Ruim op na het zoeken. Hier kan het algoritme
    bepaalde variabelen dealloceren.
\end{itemize}

Deze interface laat toe om elk gevraagd zoekalgoritme te implementeren. We
kunnen nu deze interface drie keer implementeren, met de verschillende
algoritmes. Dit gebeurde in \verb#src/search1.c#, \verb#src/search2.c# en
\verb#src/search3.c#.

Als we deze interface hebben, is het ook mogelijk om door middel van buffers
(zie \ref{buffers}) een functie te schrijven die files doorzoekt. Dit gebeurd in
\verb#src/search-files.c#.

Vervolgens maakt \verb#src/main.c# gebruik van \verb#src/search-files.c# om een
entry point te hebben. De structuur van het programma is dus een soort gelaagde
architectuur zoals ge\"illustreerd in Figuur \ref{fig:layers-main}.

Alle C files (behalve de concrete implementaties) worden dus eens gecompiled met
\verb#src/search1.c#, \verb#src/search2.c# en \verb#search3.c# — zo krijgen we
dus 3 uitvoerbare programma's.

\image[0.6]{layers-main}{Gelaagde architectuur van ons programma}

\subsection{Benchmarking}

Door gebruik te maken van een interface zoals beschreven in \ref{interface},
hebben we ook een manier om makkelijk benchmarks te schrijven. We kunnen opnieuw
gebruik maken van \verb#src/search-files.c#, we moeten enkel de bovenste laag
vervangen. De architectuur van de benchmarks is ge\"illustreerd in Figuur
\ref{fig:layers-bench}.

\image[0.6]{layers-bench}{Gelaagde architectuur van de benchmarks}

Een benchmark zal ook de bestanden die meegegeven zijn op de commandolijn
gebruiken om een string search uit te voeren, met het verschil dat dit meerdere
keren zal uitgevoerd worden, zodat er betrouwbare metingen kunnen gebeuren.
Vervolgens doet het enige postprocessing van de data, zoals bepalen van het
gemiddelde, de standaardafwijking en de uitschieters.

\subsection{Brute force}

We implementeerden ook een eenvoudig brute-force algoritme in het bestand
\verb#src/search0.c#. Dit was niet noodzakelijk maar het interessant om dit te
vergelijken met de andere algoritmes, en het kan ook gebruikt worden in
correctheidstesten.

\subsection{Werken met buffers}
\label{buffers}

Omdat \'e\'en van de vereisten is dat het doorzoeken van grote files mogelijk
is, gebruiken we buffers.

Buffers zijn nodig omdat we nooit het volledige te doorzoeken bestand in \'e\'en
keer in het werkgeheugen kunnen laden als dit groot is. We lezen het dus in per
buffer. In deze subsectie argumenteren we dat we een willekeurig exact string
matching algoritme dat werkt op een simpele array gemakkelijk kunnen uitbreiden
tot een algoritme dat op grote files werkt via buffers.

Onze strategie verloopt als volgt:

\textbf{Gegeven}:

Een initieel lege buffer $b$ met $b_{size}$ de grootte van deze buffer, en
$b_{used}$ het aantal gebruikte tekens in deze buffer. Laat $p$ ons zoekpatroon
zijn met $p_{size}$ de lengte van dit zoekpatroon. Verder is $t$ de te
doorzoeken tekst (met lengte $t_{size}$) en $a$ het gebruikte algoritme.

\textbf{Er geldt}:

\begin{itemize}
    \item initieel is de buffer leeg, dus $b_{used} = 0$;
    \item het patroon moet in de buffer passen, dus $p_{size} \leq b_{size}$.
\end{itemize}

\textbf{Algoritme}:

\begin{itemize}
    \item Zolang we het einde van de te doorzoeken tekst niet hebben bereikt,
    dus zolang $t$ niet leeg is:
    \begin{itemize}
        \item Verplaats de eerste $b_{size} - b_{used}$ tekens van $t$ naar de
        buffer $b$, de eerste $b_{used}$ tekens van $b$ blijven dus behouden.
        \item Doorzoek $b$ met het gegeven algoritme $a$.
        \item Indien er een match begint op \'e\'en van de
        laatste $p_{size} - 1$ posities in de buffer, kan deze niet gedetecteerd
        worden. Daarom verplaatsen we nu de laatste $p_{size} - 1$ tekens naar
        het begin van $b$. Nu geldt dat $b_{used} = p_{size} - 1$.
    \end{itemize}
\end{itemize}

Er is dus telkens een zeker overlap van $p_{size} - 1$ tekens, die (afhankelijk
van het algoritme) eventueel 2 keer doorzocht wordt, en zeker \'e\'enmaal
gekopi\"eerd. Een slechtste geval analyse geeft ons dat de maximale overhead
gegeven wordt door:

\begin{equation*}
\left( \lceil \frac{t_{size}}{b_{size}} \rceil - 1 \right)
    \cdot \left( p_{size} - 1 \right)
\end{equation*}

Aangezien $p_{size}$ en $t_{size}$ vastliggen, is $b_{size}$ de enige factor
waarmee we de overhead kunnen be\"invloeden. Om de overhead te minimaliseren,
moeten we $b_{size}$ dus zo groot mogelijk kiezen.

\section{Algemene optimalisaties}

\subsection{Dereferencing versnellen}

In alle algoritmes lopen we door de buffer om de string te zoeken. De klassieke
manier om dit te doen wordt in C geschreven als:

\begin{verbatim}
int i;
for(i = 0; i < buffer_size; i++) {
    /* Doe iets met buffer[i]... */
}
\end{verbatim}

In de meeste gevallen wordt \verb#buffer[i]# zeer intensief gebruikt in de body
van de lus. We kunnen dit echter ook schrijven als:

\begin{verbatim}
const char *buffer_end = buffer + buffer_size;
while(buffer < buffer_end) {
    /* Doe iets met *buffer... */
    buffer++;
}
\end{verbatim}

De waarde van \verb#*buffer# bepalen gaat sneller dan de waarde van
\verb#buffer[i]# bepalen, omdat er geen optelling nodig is. Aangezien deze
optelling meerdere keren zou gebeuren in de body van de lus, en de lus een groot
aantal keer uitgevoerd wordt, is dit een optimalisatie die de moeite loont: alle
ge\"implementeerde algoritmen werden ongeveer 10\% sneller voor voldoende grote
bestanden.

\section{Correctheidstesten}

\subsection{Testen op valse positieven}

Bij een exact string matching algoritme is het zeer makkelijk om te testen op
valse positieven. Concreet is een vals positief hier wanneer ons algoritme dat
er een match staat in file $f$ op positie $p$, en dit niet het geval is.

We schreven een tool om dit te testen, de source code hiervan is te vinden in
\verb#util/verify-matches.c#. Deze tool neemt op \verb#stdin# een aantal lijnen
van de form \verb#file_name:position#, dus de uitvoer van \'e\'en van de
zoekalgoritmes. Vervolgens zal het \'e\'en voor \'e\'en alle files openen,
zoeken naar de gegeven positie, en kijken of de zoekterm hier effectief staat.

\subsection{Parallel testen van verschillende algoritmes}

Alle verschillende algoritmes die we ge\"implementeerd hebben dienen exact
hetzelfde resultaat te geven voor dezelfde input. We kunnen dus een soort
algemene test implementeren die alle algoritmes probeert op \'e\'en inputset, en
vervolgens de uitkomsten vergelijkt.

Bovendien kunnen we gebruik maken van named pipes om een oneindig grote tekst
te genereren. Dit controleert dan ook of de buffering goed werkt — want een
oneindig groot bestand kan nooit in het werkgeheugen passen. Ook kunnen de
verschillende algoritmes parallel draaien, wat een voordeel is op moderne
multicore processors.

Hiertoe gebruiken we de utilities \verb#pipe-diff# (zie \ref{pipe-diff}) en
\verb#generate-text-and-matches# (zie \ref{generate-text-and-matches}).

We genereren voor een bepaald zoekpatroon een stroom van tekst, en laten
alle zoekalgoritmes erop los. Voor $x$ zoekalgoritmen krijgen we dus $x$
outputstromen met posities, en van \verb#generate-text-and-matches# krijgen we
nog 1 outputstroom met de verwachte posities. Vervolgens vergelijken we al deze
stromen met de \verb#pipe-diff# utility.

Het eenvoudige ruby-scriptje dat al deze stromen aanmaakt en opstart kan worden
teruggevonden in \verb#util/parallel-test.rb#.

\section{Snelheidstesten}

In deze sectie vergelijken we de snelheid van de algoritmes, toegepast op een
aantal veel voorkomende gevallen en een aantal interessante gevallen.

\section{Utilities}

\subsection{Genereren van willekeurige tekst}

We schreven een utility om willekeurige tekst te genereren. Dit is handig bij
het testen van de verschillende algoritmes.

De source code hiervan is te vinden in \verb#util/generate-text.c#. De gebruiker
kan meegeven welke karakters er gebruikt moeten worden in de willekeurige tekst
(b.v. enkel alfanumeriek, of een DNA sequentie) en hoeveel tekst er gegenereerd
moet worden.

\label{generate-text-and-matches}
Een variant bevindt zich in \verb#util/generate-text-and-matches.c#. Deze zal
naast een willekeurige tekst ook nog de verwachte matches (dus de posities
waarop een match moet voorkomen) genereren.

\subsection{Vergelijken van pipes}
\label{pipe-diff}

Om verschillende bestanden te vergelijken, gebruikt men klassiek het \verb#diff#
programma. Dit werkt echter niet goed als het de bedoeling is om named pipes
te vergelijken. Om dit op te lossen schreven we \verb#util/pipe-diff.hs#. Deze
utility is geschreven in Haskell, omdat die programmeertaal op een eenvoudige
manier threads en concurrent IO toelaat, wat nodig is als we de output van
verschillende pipes tegelijk willen vergelijken.

De utility neemt een aantal bestanden als argumenten, en zal al deze bestanden
lijn voor lijn vergelijken — ze dienen allemaal hetzelfde te zijn. Het heeft de
aangename eigenschap om ook zeer goed te werken op named pipes.

\end{document}
